# Executive Abstract (Pre-RAG Baseline)

## India–Japan Diplomatic Discourse Analysis: Baseline Readiness for Research Proposal

This pre-RAG stage establishes a transparent, reproducible, and policy-relevant baseline for analyzing strategic discourse shifts in India–Japan diplomatic documents. The baseline is intentionally classical and interpretable: it combines structured data loading, text preprocessing, lexicon-based strategic scoring (economic vs. security emphasis), tone and urgency analysis, thematic topic modeling, and statistical reporting through a unified pipeline and dashboard environment.

The core objective of this stage is methodological credibility. Before introducing RAG-based semantic retrieval, the project first demonstrates that foundational NLP outputs are stable, explainable, and traceable to explicit data artifacts. This sequencing is important for research design: it ensures that any later gains from RAG can be evaluated against a rigorous and understandable benchmark rather than against an under-specified baseline.

Recent hardening work improved both scientific reliability and practical usability. On the data side, the canonical corpus process is now non-destructive and enrichment-oriented, preserving primary files while enabling controlled updates. A staged URL backfill workflow (deterministic matching, assisted lookup, curated archive seeding, and approval-based promotion) was introduced to improve evidence traceability without compromising data integrity. On the analytics side, dashboard outputs were strengthened with confidence-aware interpretation, contradiction checks, source credibility context, and trigger-oriented framing to support policy-facing reading of results.

Operational robustness was also materially improved. External integration loading is now tied to cache-token invalidation based on file signatures, reducing stale-context risk. RSS ingestion was hardened with diagnostics and fallback logic. Report outputs were upgraded so dashboard and PDF artifacts remain aligned, including shared visual payloads and a redesigned live pulse representation (7-day activity trend, recency mix, and momentum label) that is more interpretable for decision audiences.

As of 20 February 2026, verification evidence indicates strong pre-RAG progress. The baseline test suite passes in the recommended Python 3.11 environment (`54 passed, 3 deselected`). The canonical corpus currently contains 72 documents spanning 2000-08-22 to 2026-02-20, with source diversity across MEA, MOFA, JETRO, EMBJPIN, and MOFA archive entries. External context integrations are operational across trade, statistical, open-government, RSS, and live-signal channels. Together, these outcomes show that the project has moved from prototype behavior toward research-grade baseline reliability.

At the same time, this abstract maintains realistic methodological caution. Some hardening goals remain partially complete: dependency pinning for fully frozen reproducibility, explicit source-type fielding in canonical outputs, and tighter URL completeness are still recommended before final thesis-scale comparative experiments. These are refinements rather than blockers.

In research terms, the project is now in a strong “Stage 1 complete-plus” state: the baseline is robust enough to justify proceeding to Stage 2 (RAG extension), while still preserving a clear checklist of final reproducibility controls. This supports a credible thesis narrative: first establish a transparent classical baseline, then evaluate RAG as an incremental methodological advance rather than a replacement for foundational analytical rigor.

---

### Suggested Appendix Label

**Appendix A — Executive Abstract: Pre-RAG Baseline Implementation and Validation (Feb 2026)**
